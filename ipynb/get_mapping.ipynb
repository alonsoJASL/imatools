{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "import numpy as np \n",
    "\n",
    "IMATOOLS_DIR = os.getcwd()+'/..'\n",
    "sys.path.insert(1, IMATOOLS_DIR)\n",
    "\n",
    "from imatools.common import ioutils as iou\n",
    "from imatools.common import vtktools as vtku \n",
    "\n",
    "def calc_cog(pts, el):\n",
    "    return [np.mean(pts[ee], 0) for ee in el]\n",
    "\n",
    "norm2 = lambda a : np.linalg.norm(a)\n",
    "norm_vec = lambda a : a/norm2(a)\n",
    "\n",
    "\n",
    "def extract_from_dataframe(dframe, window, bdir=None):\n",
    "    _dir = dframe.result_path[window]\n",
    "    _user = dframe.user[window].tolist()\n",
    "    _patient = dframe.patient[window].tolist()\n",
    "    _mode = dframe['mode'][window].tolist()\n",
    "    _original_dir = dframe.original_path[window]\n",
    "    _sim_dir = dframe.simulation_path[window]\n",
    "\n",
    "    if (bdir is not None):\n",
    "        _dir = [px.replace('$AFIB_REPROD', bdir) for px in _dir]\n",
    "        _original_dir = [px.replace('$AFIB_REPROD', bdir)\n",
    "                         for px in _original_dir]\n",
    "        _sim_dir = [px.replace('$AFIB_REPROD', bdir) for px in _sim_dir]\n",
    "    else:\n",
    "       _dir = _dir.tolist()\n",
    "       _sim_dir = _sim_dir.tolist()\n",
    "       _original_dir = _original_dir.tolist()\n",
    "\n",
    "    return _dir, _user, _patient, _mode, _original_dir, _sim_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Locations of hard drive based on platform\n",
    "dirdic = {'macOS': '/Volumes/sandisk',\n",
    "          'Linux': '/media/jsl19/sandisk',\n",
    "          'Windows': 'D:/'}\n",
    "\n",
    "tex_dic = {'macOS' : '/Users/jsolislemus/Documents/TEX', \n",
    "            'Linux' : '/home/jsl19/Documents/tex'}\n",
    "\n",
    "base_dir = iou.fullfile(dirdic[iou.chooseplatform()], '01_atrialfibres/06_Reproducibility/05_UserProjects')\n",
    "sims_dir = iou.fullfile(base_dir, '008_simulation_results')\n",
    "out_dir = iou.fullfile(base_dir, '009_simulation_images', 'Fibre_Agreement')\n",
    "\n",
    "tex_dir = iou.fullfile(tex_dic[iou.chooseplatform()], 'tex.cinbio.reproducibility/scripts/py')\n",
    "\n",
    "N = ['M' + str(n) for n in np.linspace(1,100,num=100, dtype=int)]\n",
    "\n",
    "\n",
    "df_tracking = pd.read_csv(iou.fullfile(base_dir, 'simulations_paths.csv'))\n",
    "num_pairs = int(len(df_tracking)/2)\n",
    "\n",
    "df_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_to_comparisons_dir(imsh, scar, fib_dir, odir, pre) : \n",
    "    \"\"\"Copies mesh files for easier comparisons \n",
    "\n",
    "    imsh_ : Original input mesh name /path/clean-Labelled-refined  \n",
    "    scar_ : /path/MaxScar_Normalised.vtk\n",
    "    fib_dir : Fibre files dir\n",
    "    odir_ : output directory\n",
    "    pre_  : Prefix (MX)\n",
    "    \"\"\"\n",
    "    exts = ['.pts', '.elem', '.lon']\n",
    "    dat_files = ['LAT_RSPV_1.dat', 'LAT_RSPV_l.dat', 'PSNode.dat', 'PSNodeSmooth.dat']\n",
    "\n",
    "    omsh = iou.fullfile(odir, pre)\n",
    "    os.makedirs(omsh, exist_ok=True)\n",
    "\n",
    "    shutil.copyfile(src=scar, dst=iou.fullfile(omsh, 'scar.vtk'))\n",
    "    shutil.copyfile(src=imsh+'.vtk', dst=iou.fullfile(omsh, 'input.vtk'))\n",
    "\n",
    "    for ix in range(len(exts)) : \n",
    "        shutil.copyfile(src=imsh+exts[ix], dst=iou.fullfile(omsh, 'input'+exts[ix]))\n",
    "\n",
    "        shutil.copyfile(src=iou.fullfile(fib_dir, 'Bilayer_1'+exts[ix]), dst=iou.fullfile(omsh, 'fibre_1'+exts[ix]))\n",
    "        shutil.copyfile(src=iou.fullfile(fib_dir, 'Bilayer_l'+exts[ix]), dst=iou.fullfile(omsh, 'fibre_l'+exts[ix]))\n",
    "        if (exts[ix] != '.lon') : \n",
    "            shutil.copyfile(src=iou.fullfile(fib_dir, 'Monolayer'+exts[ix]), dst=iou.fullfile(omsh, 'mono'+exts[ix]))\n",
    "\n",
    "    for d in dat_files : \n",
    "        shutil.copyfile(src=iou.fullfile(fib_dir, d), dst=iou.fullfile(omsh, d))\n",
    "\n",
    "def get_names_to_copy(indx, og_dir, sim_dir) : \n",
    "    imsh = iou.searchFileByType(og_dir[indx], 'clean', 'vtk')\n",
    "    imsh = imsh[0][0:-4] # /path/clean-Labelled-reg-refined (no extension)\n",
    "\n",
    "    scar = iou.fullfile(og_dir[indx], 'MaxScar_Normalised.vtk')\n",
    "    fib_dir = sim_dir[indx] \n",
    "\n",
    "    return imsh, scar, fib_dir \n",
    "\n",
    "    \n",
    "num_comparisons = 50 \n",
    "N = ['M' + str(n) for n in np.linspace(1,100,num=100, dtype=int)]\n",
    "\n",
    "pairs = np.arange(100).reshape((num_comparisons, 2))\n",
    "sim_res_dir, users, patients, mode, original_dir, _ = extract_from_dataframe(df_tracking, window=np.arange(100), bdir=base_dir)\n",
    "\n",
    "midic_comp_info = []\n",
    "for which_pair in range(num_comparisons) : \n",
    "    comparison_dir = iou.fullfile(base_dir, '011_comparisons', 'C'+str(which_pair))\n",
    "     \n",
    "    ix0 = pairs[which_pair, 0]\n",
    "    imsh0, scar0, fib_dir0 = get_names_to_copy(indx=ix0, og_dir=original_dir, sim_dir=sim_res_dir)\n",
    "    # copy_to_comparisons_dir(imsh=imsh0, scar=scar0, fib_dir=fib_dir0, odir=comparison_dir, pre=N[ix0])\n",
    "    \n",
    "    midic_comp_info.append(\n",
    "        {\n",
    "            'original_path' : original_dir[ix0], \n",
    "            'result_path' : sim_res_dir[ix0], \n",
    "            'comparison_path' : iou.fullfile(comparison_dir, N[ix0]),\n",
    "            'mode' : mode[ix0], \n",
    "            'processing' : df_tracking.iloc[ix0].processing \n",
    "        }\n",
    "    ) \n",
    "\n",
    "    ix1 = pairs[which_pair, 1]\n",
    "    imsh1, scar1, fib_dir1 = get_names_to_copy(indx=ix1, og_dir=original_dir, sim_dir=sim_res_dir)\n",
    "    # copy_to_comparisons_dir(imsh=imsh1, scar=scar1, fib_dir=fib_dir1, odir=comparison_dir, pre=N[ix1])\n",
    "\n",
    "    midic_comp_info.append(\n",
    "        {\n",
    "            'original_path' : original_dir[ix1], \n",
    "            'result_path' : sim_res_dir[ix1], \n",
    "            'comparison_path' : iou.fullfile(comparison_dir, N[ix1]),\n",
    "            'mode' : mode[ix1], \n",
    "            'processing' : df_tracking.iloc[ix1].processing \n",
    "        }\n",
    "    ) \n",
    "\n",
    "comparisons_ofile = iou.fullfile(base_dir, '011_comparisons', 'comparisons_path.csv')\n",
    "df_comparisons = pd.DataFrame(midic_comp_info)\n",
    "df_comparisons.to_csv(comparisons_ofile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load one mesh and create a mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "\n",
    "num_comparisons = 50 \n",
    "N = ['M' + str(n) for n in np.linspace(1,100,num=100, dtype=int)]\n",
    "\n",
    "# pairs = np.arange(100).reshape((num_comparisons, 2))\n",
    "# sim_res_dir, users, patients, _, original_dir, _ = extract_from_dataframe(df, window=np.arange(100), bdir=base_dir)\n",
    "\n",
    "comparison_dir = [iou.fullfile(base_dir, '011_comparisons', 'C'+str(c)) for c in np.arange(num_comparisons)]\n",
    "\n",
    "cx=0\n",
    "\n",
    "this_comparison = comparison_dir[cx]\n",
    "sub_dirs = os.listdir(this_comparison)\n",
    "names = {'scar' : 'scar', 'l' : 'fibre_l', '1' : 'fibre_1', 'in' : 'input'}\n",
    "\n",
    "which_name = 'in' # in, scar, l, 1\n",
    "mname_ext = names[which_name] + '.vtk'\n",
    "type_of_mapping = 'elem' # elem, pts\n",
    "\n",
    "id_left = sub_dirs[0]\n",
    "id_right = sub_dirs[1]\n",
    "path_left = iou.fullfile(this_comparison, id_left, mname_ext)\n",
    "path_right = iou.fullfile(this_comparison, id_right, mname_ext)\n",
    "\n",
    "midic = vtku.create_mapping(msh_left_name=path_left, msh_right_name=path_right, left_id=id_left, right_id=id_right, map_type=type_of_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert CARP meshes to vtk, then extract all the magnitudes of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_comparisons = pd.read_csv(iou.fullfile(base_dir, '011_comparisons', 'comparisons_path.csv'))\n",
    "cpaths = df_comparisons.comparison_path.tolist()\n",
    "\n",
    "ff = '1' # Choose fibre file {1, l}\n",
    "\n",
    "cpaths = [c.replace('/Volumes', '/media/jsl19') for c in cpaths]\n",
    "\n",
    "for cp in cpaths :\n",
    "    this_ff = iou.fullfile(cp, 'fibre_'+ff)\n",
    "    os.system('meshtool convert -imsh={} -ifmt=carp_txt -omsh={} -ofmt=vtk_polydata -scale=1e-3'.format(this_ff, this_ff))\n",
    "\n",
    "    lat=iou.fullfile(cp, 'LAT_RSPV_'+ff+'.dat')\n",
    "    olat=iou.fullfile(cp, 'lat_'+ff)\n",
    "    os.system('meshtool extract gradient -msh={} -ifmt=carp_txt -idat={} -odat={}'.format(this_ff, lat, olat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparisons = pd.read_csv(iou.fullfile(\n",
    "    base_dir, '011_comparisons', 'comparisons_path.csv'))\n",
    "cpaths = df_comparisons.comparison_path.tolist()\n",
    "\n",
    "ff = 'l'  # Choose fibre file {1, l}\n",
    "\n",
    "cpaths = [c.replace('/Volumes', '/media/jsl19') for c in cpaths]\n",
    "\n",
    "for cp in cpaths:\n",
    "    this_ff = iou.fullfile(cp, 'fibre_'+ff)\n",
    "    os.system('meshtool extract mesh -msh={} -ifmt=carp_txt -submsh={}_endo -ofmt=carp_txt -tags=11,13,21,23,25,27'.format(this_ff, this_ff))\n",
    "    os.system('meshtool extract mesh -msh={} -ifmt=carp_txt -submsh={}_epi  -ofmt=carp_txt -tags=12,14,22,24,26,28'.format(this_ff, this_ff))\n",
    "\n",
    "    os.system('meshtool convert -imsh={}_endo -ifmt=carp_txt -omsh={}_endo -ofmt=vtk_polydata -scale=1e-3'.format(this_ff, this_ff))\n",
    "    os.system('meshtool convert -imsh={}_epi -ifmt=carp_txt -omsh={}_epi -ofmt=vtk_polydata -scale=1e-3'.format(this_ff, this_ff))\n",
    "# meshtool extract mesh -msh=fibre_1 -tags=11,13,21,23,25,27 -submsh=fibre_1_endo -ifmt=carp_txt -ofmt=carp_txt\n",
    "# meshtool extract mesh -msh=fibre_1 -tags=12,14,22,24,26,28 -submsh=fibre_1_epi -ifmt=carp_txt -ofmt=carp_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dir = iou.fullfile(base_dir, '011_comparisons')\n",
    "df_comparisons = pd.read_csv(iou.fullfile(comparison_dir, 'comparisons_path.csv'))\n",
    "\n",
    "CX = os.listdir(comparison_dir)\n",
    "if 'comparisons_path.csv' in CX:\n",
    "    CX.remove('comparisons_path.csv')\n",
    "\n",
    "cx = 0\n",
    "\n",
    "this_comparison = CX[cx]\n",
    "mapping_files_dir = iou.fullfile(comparison_dir, this_comparison, 'MAPPING')\n",
    "\n",
    "\n",
    "files_and_mapping = {\n",
    "    'lat' : ('LAT_RSPV_X.dat', 'fibre_X_pts.csv'), \n",
    "    'gradlat': ('lat_X.gradmag.dat', 'fibre_X_pts.csv'), \n",
    "    'ps' : ('PSNodeSmooth.dat', 'input_pts.csv'), \n",
    "    'f_endo' : ('fibre_X_endo.lon', 'fibre_X_endo_elem.csv'),\n",
    "    'f_epi' : ('fibre_X_epi.lon', 'fibre_X_epi_elem.csv')\n",
    "}\n",
    "\n",
    "dx = 'gradlat'\n",
    "mx = 'l'\n",
    "\n",
    "dat_file = files_and_mapping[dx][0].replace('X', mx)\n",
    "map_name = files_and_mapping[dx][1].replace('X', mx)\n",
    "\n",
    "iou.cout('COMPARISON: {}'.format(dat_file))\n",
    "iou.cout('mapping: {}'.format(map_name))\n",
    "\n",
    "df = pd.read_csv(iou.fullfile(mapping_files_dir, map_name))\n",
    "total = len(df)\n",
    "\n",
    "case0 = df.columns[0]\n",
    "case1 = df.columns[1]\n",
    "idx0 = df[case0]\n",
    "idx1 = df[case1]\n",
    "\n",
    "dist_max = 1 # mm \n",
    "\n",
    "iou.cout('Adjust for maximum distance = {} mm'.format(dist_max))\n",
    "\n",
    "idx0 = idx0[df.distance_manual >= 1]\n",
    "idx1 = idx1[df.distance_manual >= 1]\n",
    "\n",
    "# if dat_file == '' : # loading scar \n",
    "#\n",
    "# else :\n",
    "arr0 = np.loadtxt(iou.fullfile(comparison_dir, this_comparison, case0, dat_file))\n",
    "arr1 = np.loadtxt(iou.fullfile(comparison_dir, this_comparison, case1, dat_file))\n",
    "\n",
    "if dx == 'gradlat' : \n",
    "    arr_idx0 = 1/arr0[idx0]\n",
    "    arr_idx1 = 1/arr1[idx1]\n",
    "else : \n",
    "    arr_idx0 = arr0[idx0]\n",
    "    arr_idx1 = arr1[idx1]\n",
    "\n",
    "if dx == 'ps' : \n",
    "    print(np.corrcoef(arr_idx0, arr_idx1))\n",
    "else : \n",
    "    print(np.linalg.norm(arr_idx0-arr_idx1))\n",
    "\n",
    "# check that mapping makes sense, compare with normal arrays, then compare \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development of techniques below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "\n",
    "num_comparisons = 50 \n",
    "N = ['M' + str(n) for n in np.linspace(1,100,num=100, dtype=int)]\n",
    "\n",
    "# pairs = np.arange(100).reshape((num_comparisons, 2))\n",
    "# sim_res_dir, users, patients, _, original_dir, _ = extract_from_dataframe(df, window=np.arange(100), bdir=base_dir)\n",
    "\n",
    "comparison_dir = [iou.fullfile(base_dir, '011_comparisons', 'C'+str(c)) for c in np.arange(num_comparisons)]\n",
    "\n",
    "cx=0\n",
    "\n",
    "this_comparison = comparison_dir[cx]\n",
    "sub_dirs = os.listdir(this_comparison)\n",
    "names = {'scar' : 'scar', 'l' : 'fibre_l', '1' : 'fibre_1', 'in' : 'input'}\n",
    "\n",
    "# when input is only vtk (scar)\n",
    "path_left = iou.fullfile(this_comparison, sub_dirs[0])\n",
    "path_right = iou.fullfile(this_comparison, sub_dirs[1])\n",
    "\n",
    "which_name = 'in' # in, scar, l, 1\n",
    "mname_ext = names[which_name] + '.vtk'\n",
    "type_of_mapping = 'elem' # elem, pts\n",
    "\n",
    "msh_left = vtku.readVtk(iou.fullfile(path_left, mname_ext))\n",
    "msh_right = vtku.readVtk(iou.fullfile(path_right, mname_ext))\n",
    "\n",
    "# cells \n",
    "tot_left = msh_left.GetNumberOfCells()\n",
    "tot_right = msh_right.GetNumberOfCells() \n",
    "\n",
    "path_large = path_left  # 0\n",
    "path_small = path_right # 1\n",
    "tot_large = tot_left\n",
    "tot_small = tot_right\n",
    "sdir_large = sub_dirs[0]\n",
    "sdir_small = sub_dirs[1]\n",
    "\n",
    "if tot_left < tot_right : \n",
    "    path_large = path_right\n",
    "    path_small = path_left\n",
    "    tot_large = tot_right\n",
    "    tot_small = tot_left\n",
    "    sdir_large = sub_dirs[1]\n",
    "    sdir_small = sub_dirs[0]\n",
    "\n",
    "msh_small = vtku.readVtk(iou.fullfile(path_small, mname_ext)) # 1\n",
    "cog_small = vtku.getCentreOfGravity(msh_small)\n",
    "\n",
    "msh_large = vtku.readVtk(iou.fullfile(path_large, mname_ext)) # 0\n",
    "\n",
    "cell_locate_on_large=vtk.vtkCellLocator()\n",
    "cell_locate_on_large.SetDataSet(msh_large)\n",
    "cell_locate_on_large.BuildLocator()\n",
    "\n",
    "cell_ids_small = np.arange(tot_small)\n",
    "cell_ids_large = np.zeros(tot_small, dtype=int)\n",
    "l2_norm_manual = np.zeros(tot_small, dtype=float)\n",
    "l2_norm_filter = np.zeros(tot_small, dtype=float)\n",
    "x_cog_small = cog_small[:, 0]\n",
    "y_cog_small = cog_small[:, 1]\n",
    "z_cog_small = cog_small[:, 2]\n",
    "x_in_large = np.zeros(tot_small, dtype=float)\n",
    "y_in_large = np.zeros(tot_small, dtype=float)\n",
    "z_in_large = np.zeros(tot_small, dtype=float)\n",
    "\n",
    "for ix in range(tot_small): # tot_small\n",
    "    cellId_in_large = vtk.reference(0)\n",
    "    c_in_large = [0.0, 0.0, 0.0]\n",
    "    subId = vtk.reference(0)\n",
    "    dist_to_large = vtk.reference(0.0)\n",
    "\n",
    "    cell_locate_on_large.FindClosestPoint(cog_small[ix], c_in_large, cellId_in_large, vtk.reference(0), dist_to_large)\n",
    "    cell_ids_large[ix] = cellId_in_large.get()\n",
    "\n",
    "    l2_norm_manual[ix] = np.linalg.norm(cog_small[ix]-c_in_large)\n",
    "    l2_norm_filter[ix] = dist_to_large\n",
    "    \n",
    "    x_in_large[ix] = c_in_large[0]\n",
    "    y_in_large[ix] = c_in_large[1]\n",
    "    z_in_large[ix] = c_in_large[2]\n",
    "\n",
    "midic = {\n",
    "    sdir_small : cell_ids_small, \n",
    "    sdir_large : cell_ids_large, \n",
    "    'distance_manual' : l2_norm_manual, \n",
    "    'distance_auto'  : l2_norm_filter, \n",
    "    'X_'+sdir_small.lower() : x_cog_small, \n",
    "    'Y_'+sdir_small.lower() : y_cog_small, \n",
    "    'Z_'+sdir_small.lower() : z_cog_small, \n",
    "    'X_'+sdir_large.lower() : x_in_large,\n",
    "    'Y_'+sdir_large.lower() : y_in_large,\n",
    "    'Z_'+sdir_large.lower() : z_in_large\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(midic)\n",
    "out_dir = iou.fullfile(this_comparison, 'MAPPING')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "df.to_csv(iou.fullfile(out_dir, names[which_name] + '_' + type_of_mapping + '.csv'), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2f='/media/jsl19/sandisk/01_atrialfibres/06_Reproducibility/05_UserProjects/011_comparisons/C0/M1'\n",
    "\n",
    "pts_1, el_1, r_1 = iou.loadCarpMesh('fibre_1', p2f)\n",
    "pts_l, el_l, r_l = iou.loadCarpMesh('fibre_l', p2f)\n",
    "np.unique(r_l)\n",
    "np.unique(r_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('imatools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ef3cfad9850278225e497b94f7d476aa408699f40230bdd18bf3034bae757d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
